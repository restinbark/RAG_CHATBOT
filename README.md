# 💬 CrediTrust RAG Chatbot

A Retrieval-Augmented Generation (RAG) chatbot that answers questions from customer complaint data using a combination of semantic search and language generation. Built during Week 6 of the **10Academy AI Mastery Program**.

This project uses:
- ⚙️ Sentence embeddings (MiniLM)
- 🧠 Vector similarity search (FAISS)
- 🤖 LLM generation (Flan-T5)
- 🌐 Streamlit web app

---

## 🎯 Use Case

> Ask questions like:
> - "Why are customers unhappy with Buy Now Pay Later?"
> - "What complaints exist about credit cards?"

And get:
- ✅ A summarized answer generated by the model
- ✅ Top complaint snippets from the actual dataset

---

## 📂 Folder Structure

rag_chatbot/
├── app/
│ └── app.py # Streamlit UI
├── data/
│ ├── complaints.csv.zip # Original complaint data
│ └── filtered_complaints.csv # Cleaned data used for vectorization
├── notebooks/
  ├── eda_preprocessing.ipynb # EDA and filtering notebook
│ └── test_file.ipynb
├── src/
│ ├── chunking.py # Splits complaint text into chunks
│ ├── embed_index.py # Embeds and indexes chunks into FAISS
│ └── rag_pipeline.py # Query, retrieve, and generate answers
├── vector_store/
│ └── faiss_index/
│ ├── faiss.index # FAISS vector index
│ └── metadata.pkl # Corresponding text chunks
├── setup_folders.py # Utility for folder setup
├── requirements.txt # Python dependencies
├── .gitignore
└── README.md # You're here!


---

## 🧠 RAG Pipeline Overview

```mermaid
flowchart TD
    A[User Enters Question] --> B[Embed Question (MiniLM)]
    B --> C[Search FAISS Vector Store]
    C --> D[Retrieve Top-k Complaint Chunks]
    D --> E[Generate Answer with Flan-T5]
    E --> F[Streamlit UI: Show Answer + Sources]

🛠️ Setup & Run
1. Clone the repo

git clone https://github.com/yourusername/rag_chatbot.git
cd rag_chatbot

2. Set up virtual environment
bash
python -m venv .venv
.venv\Scripts\activate    # On Windows

3. Install dependencies

pip install -r requirements.txt

4. Prepare data & vector store
You must first run:

  bash

  python src/embed_index.py

This will:

Read the filtered complaint data

Embed text chunks using MiniLM

Save faiss.index and metadata.pkl to vector_store/faiss_index/

5. Launch the chatbot

bash

streamlit run app/app.py

Then open your browser to http://localhost:8501

🧪 Example Output
Q: Why are customers unhappy with Buy Now Pay Later?

📘 Answer:

...they waited this long to do so because they wanted more money... slow and inconvenient payment methods...

📚 Sources:

“...would make it right for their customer that always pay more than due...”

“...clearly want to make things difficult for their customers...”

“...happy collecting late charges without providing due process...”

✅ Features
✅ Streamlit chatbot with input field and Ask button

✅ Product-based filtering (BNPL, Credit Card, etc.)

✅ 10 top-matching complaint snippets retrieved per query

✅ Compact, interpretable answers generated via Flan-T5

🔧 Tech Stack

| Layer     | Library                          |
| --------- | -------------------------------- |
| Embedding | `sentence-transformers` (MiniLM) |
| Vector DB | `faiss-cpu`                      |
| LLM       | `transformers` (Flan-T5)         |
| Web UI    | `streamlit`                      |
| Data      | Real-world complaints            |

👨‍💻 Author
Barkilign Mulatu
AI Fellow @ 10Academy

📜 License
This project is for educational and non-commercial use only.
Built for the 10Academy Week 6 GenAI Project